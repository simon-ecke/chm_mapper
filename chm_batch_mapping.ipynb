{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b547ec1d",
   "metadata": {},
   "source": [
    "# CHM Batch Mapper - Multiple Canopy Height Model Processing\n",
    "\n",
    "This notebook processes **multiple CHM files** in batch mode and generates high-quality PDF maps for each.\n",
    "\n",
    "## Batch Processing Features\n",
    "- Process all CHM files in a folder automatically\n",
    "- Single vector file used for all CHMs\n",
    "  - **Supported formats:** `.gpkg` (GeoPackage), `.shp` (Shapefile), `.kml`, `.geojson`\n",
    "- Automatic detection of overlapping vectors for each CHM\n",
    "- Individual PDF map for each CHM file\n",
    "- Progress tracking and error handling\n",
    "- Consistent map styling across all outputs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6093dfa2",
   "metadata": {},
   "source": [
    "## 1. Setup and Imports\n",
    "\n",
    "First, let's import all necessary libraries and our custom CHM mapper module."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80fafc14",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ All imports successful!\n",
      "✓ Module reloaded - any code changes are now active\n"
     ]
    }
   ],
   "source": [
    "# Standard libraries\n",
    "import os\n",
    "import glob\n",
    "from pathlib import Path\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from datetime import datetime\n",
    "\n",
    "# Geospatial libraries\n",
    "import rasterio\n",
    "from rasterio.mask import mask\n",
    "from rasterio.transform import array_bounds\n",
    "import geopandas as gpd\n",
    "from shapely.geometry import box\n",
    "\n",
    "# Our custom CHM mapper from modules folder\n",
    "import importlib\n",
    "import modules.chm_mapper as chm_mapper\n",
    "importlib.reload(chm_mapper)\n",
    "from modules.chm_mapper import CHMMapper\n",
    "\n",
    "# Display settings\n",
    "%matplotlib inline\n",
    "plt.rcParams['figure.dpi'] = 100\n",
    "\n",
    "print(\"✓ All imports successful!\")\n",
    "print(\"✓ Module reloaded - any code changes are now active\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "447ca262",
   "metadata": {},
   "source": [
    "## 2. Define Batch Processing Paths\n",
    "\n",
    "**Input:**\n",
    "- **CHM Folder:** Directory containing multiple CHM GeoTIFF files\n",
    "- **Vector Path:** Can be either:\n",
    "  - A single vector file (`.gpkg`, `.shp`, `.kml`, `.geojson`)\n",
    "  - A folder containing multiple vector files (will auto-discover all supported formats)\n",
    "- **GeoPackage (`.gpkg`) is recommended for best performance**\n",
    "\n",
    "**Output:**\n",
    "- Individual PDF map for each CHM file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fab0fe2c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CHM folder: D:\\Drohnendaten\\15_FESMART\\01_Daten\\06_AELF-Cham\\02_Data_output\\CHMs\\Zandt\n",
      "Vector path: D:\\Drohnendaten\\15_FESMART\\01_Daten\\06_AELF-Cham\\00_Planung\\Shapes FE\\Zandt\n",
      "CSV folder: D:\\Drohnendaten\\15_FESMART\\01_Daten\\06_AELF-Cham\\00_Planung\\Info\n",
      "Merge key column: 'afl'\n",
      "Output directory: D:\\Drohnendaten\\15_FESMART\\01_Daten\\06_AELF-Cham\\03_Mapping_output\\Zandt\n",
      "Location field: 'name_eigen'\n",
      "Clip to shapes: True (buffer 30 m)\n",
      "Subtitle format: '_lage1_lage2_...'\n",
      "\n",
      "✓ Vector folder detected - searching for vector files...\n",
      "Found 1 vector file(s):\n",
      "  1. Zandt.shp\n",
      "\n",
      "Searching for CHM files...\n",
      "Found 5 CHM file(s):\n",
      "  1. 20250909_066_Zandt-13305024_M3E_CHM.tif\n",
      "  2. 20250909_067_Zandt-17655713_M3E_CHM.tif\n",
      "  3. 20250909_068_Zandt-5187721_M3E_CHM.tif\n",
      "  4. 20250909_069_Zandt-14027838_M3E_CHM.tif\n",
      "  5. 20250909_070_Zandt-1158151_M3E_CHM.tif\n"
     ]
    }
   ],
   "source": [
    "# Folder containing multiple CHM GeoTIFF files\n",
    "chm_folder = r\"data/chm_files\"  # Update this path to your CHM folder\n",
    "\n",
    "# Path to your vector data - can be either:\n",
    "# 1. A single vector file: vector.gpkg, vector.shp, vector.kml, vector.geojson\n",
    "# 2. A folder containing multiple vector files (will auto-discover all supported formats)\n",
    "vector_path = r\"data/vector_files\"  # Update this path to your vector folder or file\n",
    "\n",
    "# Path to CSV files (optional) - set to None if no CSV files available\n",
    "# CSV files should have the same name as shapefile (e.g., Arrach.shp -> Arrach.csv)\n",
    "# Will be used to merge additional data if fields are missing from shapefile\n",
    "csv_folder = None  # Set to your CSV folder path if needed, e.g., r\"data/csv_files\"\n",
    "\n",
    "# Merge key column (must exist in both shapefile and CSV)\n",
    "MERGE_KEY_COLUMN = \"afl\"  # Column used to merge shapefile and CSV data\n",
    "\n",
    "# Output directory for batch maps\n",
    "output_dir = r\"output/batch_maps\"\n",
    "os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "# Custom Field Configuration\n",
    "# Location Name: extracted from shapefile field (shown once if unique)\n",
    "LOCATION_FIELD = \"name\"  # Field for location name (e.g., \"Forest_Area_1\")\n",
    "\n",
    "# Subtitle Configuration\n",
    "# Format: \"FIELD1\" + \"_\" + \"FIELD2_value1\" + \"_\" + \"FIELD2_value2\" + ...\n",
    "# Example with default settings: \"Area_1a_1b_2a\"\n",
    "SUBTITLE_USE_CUSTOM_FORMAT = True  # Set to False to use CHM filename\n",
    "SUBTITLE_FIELD1 = \"\"  # First field (usually location name, shows once if unique)\n",
    "SUBTITLE_FIELD2 = \"id\"  # Second field (shows all unique values, e.g., compartments)\n",
    "\n",
    "# Clipping Configuration\n",
    "CLIP_TO_SHAPES = True         # If True, clip CHM to shapes extent\n",
    "CLIP_BUFFER_METERS = 30       # Buffer (meters) around shapes when clipping\n",
    "\n",
    "print(f\"CHM folder: {chm_folder}\")\n",
    "print(f\"Vector path: {vector_path}\")\n",
    "print(f\"Output directory: {output_dir}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d00992f7",
   "metadata": {},
   "source": [
    "## 3. Inspect Vector Data\n",
    "\n",
    "Let's check the vector data that will be used for the CHMs."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31ac5c41",
   "metadata": {},
   "source": [
    "## 3a. Test CSV Merge (Diagnostic)\n",
    "\n",
    "Let's manually test the CSV merge to verify it's working correctly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "b982277e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing with vector file: Zandt.shp\n",
      "CSV folder: D:\\Drohnendaten\\15_FESMART\\01_Daten\\06_AELF-Cham\\00_Planung\\Info\n",
      "\n",
      "1. Shapefile columns: ['objectid', 'gemeinde', 'gmkgcode', 'zaehler', 'nenner', 'zaeh_nenn', 'afl', 'egtid', 'name_eigen', 'vorname', 'anrede', 'namensbest', 'akademisch', 'geburtsnam', 'geburtsdat', 'strassehau', 'plz', 'ort', 'herkunft', 'amtsgerich', 'grundbuchb', 'miteigentu', 'artrechtsg', 'anteileige', 'buchungsar', 'lfdnrbesta', 'flstkennz', 'gbbz', 'blatt', 'aelf_kurz', 'globalid', 'geometry']\n",
      "   Number of features: 9\n",
      "   'afl' values: [24170, 7465, 480, 5170, 4305, 8417, 2476, 71096, 1500]\n",
      "\n",
      "2. Looking for CSV: D:\\Drohnendaten\\15_FESMART\\01_Daten\\06_AELF-Cham\\00_Planung\\Info\\Zandt.csv\n",
      "   CSV exists: True\n",
      "\n",
      "3. CSV loaded successfully with encoding: cp1252, separator: ';'\n",
      "   CSV columns: ['Gemeinde', 'gmkgcode', 'zaehler', 'nenner', 'afl', 'lage', 'gemeinde', 'zaeh_nenn', 'Fläche [qm]:']\n",
      "   Number of rows: 9\n",
      "   'afl' values: [5170, 8417, 71096, 7465, 480, 4305, 2476, 1500, 24170]\n",
      "\n",
      "   CSV Preview:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Gemeinde</th>\n",
       "      <th>gmkgcode</th>\n",
       "      <th>zaehler</th>\n",
       "      <th>nenner</th>\n",
       "      <th>afl</th>\n",
       "      <th>lage</th>\n",
       "      <th>gemeinde</th>\n",
       "      <th>zaeh_nenn</th>\n",
       "      <th>Fläche [qm]:</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Zandt</td>\n",
       "      <td>5154</td>\n",
       "      <td>371</td>\n",
       "      <td>6</td>\n",
       "      <td>5170</td>\n",
       "      <td>Auf der Riesel</td>\n",
       "      <td>372177</td>\n",
       "      <td>371/6</td>\n",
       "      <td>5.167,59</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>NaN</td>\n",
       "      <td>5154</td>\n",
       "      <td>371</td>\n",
       "      <td>39</td>\n",
       "      <td>8417</td>\n",
       "      <td>Auholz</td>\n",
       "      <td>372177</td>\n",
       "      <td>371/39</td>\n",
       "      <td>8.425,11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>NaN</td>\n",
       "      <td>5161</td>\n",
       "      <td>314</td>\n",
       "      <td>34</td>\n",
       "      <td>71096</td>\n",
       "      <td>Pfahlholz</td>\n",
       "      <td>372143</td>\n",
       "      <td>314/34</td>\n",
       "      <td>71.693,80</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>NaN</td>\n",
       "      <td>5154</td>\n",
       "      <td>247</td>\n",
       "      <td>1</td>\n",
       "      <td>7465</td>\n",
       "      <td>Aufelder</td>\n",
       "      <td>372177</td>\n",
       "      <td>247/1</td>\n",
       "      <td>7.471,83</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>NaN</td>\n",
       "      <td>5154</td>\n",
       "      <td>789</td>\n",
       "      <td>2</td>\n",
       "      <td>480</td>\n",
       "      <td>Ochsenweide</td>\n",
       "      <td>372177</td>\n",
       "      <td>789/2</td>\n",
       "      <td>482,88</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Gemeinde  gmkgcode  zaehler  nenner    afl            lage  gemeinde  \\\n",
       "0    Zandt      5154      371       6   5170  Auf der Riesel    372177   \n",
       "1      NaN      5154      371      39   8417          Auholz    372177   \n",
       "2      NaN      5161      314      34  71096       Pfahlholz    372143   \n",
       "3      NaN      5154      247       1   7465        Aufelder    372177   \n",
       "4      NaN      5154      789       2    480     Ochsenweide    372177   \n",
       "\n",
       "  zaeh_nenn Fläche [qm]:  \n",
       "0     371/6     5.167,59  \n",
       "1    371/39     8.425,11  \n",
       "2    314/34    71.693,80  \n",
       "3     247/1     7.471,83  \n",
       "4     789/2       482,88  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "4. Attempting merge on 'afl'...\n",
      "   ✓ Merge successful!\n",
      "   Merged columns: ['objectid', 'gemeinde', 'gmkgcode', 'zaehler', 'nenner', 'zaeh_nenn', 'afl', 'egtid', 'name_eigen', 'vorname', 'anrede', 'namensbest', 'akademisch', 'geburtsnam', 'geburtsdat', 'strassehau', 'plz', 'ort', 'herkunft', 'amtsgerich', 'grundbuchb', 'miteigentu', 'artrechtsg', 'anteileige', 'buchungsar', 'lfdnrbesta', 'flstkennz', 'gbbz', 'blatt', 'aelf_kurz', 'globalid', 'geometry', 'Gemeinde', 'gmkgcode_csv', 'zaehler_csv', 'nenner_csv', 'lage', 'gemeinde_csv', 'zaeh_nenn_csv', 'Fläche [qm]:']\n",
      "\n",
      "   ✓✓✓ 'lage' column is present!\n",
      "   'lage' values: ['Hohe Rieder', 'Aufelder', 'Ochsenweide', 'Auf der Riesel', 'Berghäusl', 'Auholz', 'Hohe Rieder', 'Pfahlholz', 'Berghäusl']\n",
      "\n",
      "   Merged data preview:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>objectid</th>\n",
       "      <th>gemeinde</th>\n",
       "      <th>gmkgcode</th>\n",
       "      <th>zaehler</th>\n",
       "      <th>nenner</th>\n",
       "      <th>zaeh_nenn</th>\n",
       "      <th>afl</th>\n",
       "      <th>egtid</th>\n",
       "      <th>name_eigen</th>\n",
       "      <th>vorname</th>\n",
       "      <th>...</th>\n",
       "      <th>aelf_kurz</th>\n",
       "      <th>globalid</th>\n",
       "      <th>Gemeinde</th>\n",
       "      <th>gmkgcode_csv</th>\n",
       "      <th>zaehler_csv</th>\n",
       "      <th>nenner_csv</th>\n",
       "      <th>lage</th>\n",
       "      <th>gemeinde_csv</th>\n",
       "      <th>zaeh_nenn_csv</th>\n",
       "      <th>Fläche [qm]:</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1158151</td>\n",
       "      <td>372177</td>\n",
       "      <td>5154</td>\n",
       "      <td>794</td>\n",
       "      <td>0</td>\n",
       "      <td>794/0</td>\n",
       "      <td>24170</td>\n",
       "      <td>095154_1210_1</td>\n",
       "      <td>Gemeinde Zandt</td>\n",
       "      <td>None</td>\n",
       "      <td>...</td>\n",
       "      <td>ch</td>\n",
       "      <td>{AF1ACD63-6327-49E9-A492-416D3BD5043E}</td>\n",
       "      <td>NaN</td>\n",
       "      <td>5154</td>\n",
       "      <td>794</td>\n",
       "      <td>0</td>\n",
       "      <td>Hohe Rieder</td>\n",
       "      <td>372177</td>\n",
       "      <td>794/0</td>\n",
       "      <td>24.345,41</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>5187721</td>\n",
       "      <td>372177</td>\n",
       "      <td>5154</td>\n",
       "      <td>247</td>\n",
       "      <td>1</td>\n",
       "      <td>247/1</td>\n",
       "      <td>7465</td>\n",
       "      <td>095154_1210_1</td>\n",
       "      <td>Gemeinde Zandt</td>\n",
       "      <td>None</td>\n",
       "      <td>...</td>\n",
       "      <td>ch</td>\n",
       "      <td>{CE64DB4E-728A-4FBF-8821-59D7821819DA}</td>\n",
       "      <td>NaN</td>\n",
       "      <td>5154</td>\n",
       "      <td>247</td>\n",
       "      <td>1</td>\n",
       "      <td>Aufelder</td>\n",
       "      <td>372177</td>\n",
       "      <td>247/1</td>\n",
       "      <td>7.471,83</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>7896069</td>\n",
       "      <td>372177</td>\n",
       "      <td>5154</td>\n",
       "      <td>789</td>\n",
       "      <td>2</td>\n",
       "      <td>789/2</td>\n",
       "      <td>480</td>\n",
       "      <td>095154_1210_1</td>\n",
       "      <td>Gemeinde Zandt</td>\n",
       "      <td>None</td>\n",
       "      <td>...</td>\n",
       "      <td>ch</td>\n",
       "      <td>{1D9636EF-89D5-4C13-9576-38F86FF02784}</td>\n",
       "      <td>NaN</td>\n",
       "      <td>5154</td>\n",
       "      <td>789</td>\n",
       "      <td>2</td>\n",
       "      <td>Ochsenweide</td>\n",
       "      <td>372177</td>\n",
       "      <td>789/2</td>\n",
       "      <td>482,88</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>13305024</td>\n",
       "      <td>372177</td>\n",
       "      <td>5154</td>\n",
       "      <td>371</td>\n",
       "      <td>6</td>\n",
       "      <td>371/6</td>\n",
       "      <td>5170</td>\n",
       "      <td>095154_1210_1</td>\n",
       "      <td>Gemeinde Zandt</td>\n",
       "      <td>None</td>\n",
       "      <td>...</td>\n",
       "      <td>ch</td>\n",
       "      <td>{195B01BB-49D5-4D20-B1CD-9DA3ECBD5B59}</td>\n",
       "      <td>Zandt</td>\n",
       "      <td>5154</td>\n",
       "      <td>371</td>\n",
       "      <td>6</td>\n",
       "      <td>Auf der Riesel</td>\n",
       "      <td>372177</td>\n",
       "      <td>371/6</td>\n",
       "      <td>5.167,59</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>13437600</td>\n",
       "      <td>372177</td>\n",
       "      <td>5154</td>\n",
       "      <td>786</td>\n",
       "      <td>0</td>\n",
       "      <td>786/0</td>\n",
       "      <td>4305</td>\n",
       "      <td>095154_1210_1</td>\n",
       "      <td>Gemeinde Zandt</td>\n",
       "      <td>None</td>\n",
       "      <td>...</td>\n",
       "      <td>ch</td>\n",
       "      <td>{43A29E44-F662-4FFB-A690-62E4D050948D}</td>\n",
       "      <td>NaN</td>\n",
       "      <td>5154</td>\n",
       "      <td>786</td>\n",
       "      <td>0</td>\n",
       "      <td>Berghäusl</td>\n",
       "      <td>372177</td>\n",
       "      <td>786/0</td>\n",
       "      <td>4.309,08</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 39 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   objectid  gemeinde  gmkgcode  zaehler  nenner zaeh_nenn    afl  \\\n",
       "0   1158151    372177      5154      794       0     794/0  24170   \n",
       "1   5187721    372177      5154      247       1     247/1   7465   \n",
       "2   7896069    372177      5154      789       2     789/2    480   \n",
       "3  13305024    372177      5154      371       6     371/6   5170   \n",
       "4  13437600    372177      5154      786       0     786/0   4305   \n",
       "\n",
       "           egtid      name_eigen vorname  ... aelf_kurz  \\\n",
       "0  095154_1210_1  Gemeinde Zandt    None  ...        ch   \n",
       "1  095154_1210_1  Gemeinde Zandt    None  ...        ch   \n",
       "2  095154_1210_1  Gemeinde Zandt    None  ...        ch   \n",
       "3  095154_1210_1  Gemeinde Zandt    None  ...        ch   \n",
       "4  095154_1210_1  Gemeinde Zandt    None  ...        ch   \n",
       "\n",
       "                                 globalid Gemeinde gmkgcode_csv zaehler_csv  \\\n",
       "0  {AF1ACD63-6327-49E9-A492-416D3BD5043E}      NaN         5154         794   \n",
       "1  {CE64DB4E-728A-4FBF-8821-59D7821819DA}      NaN         5154         247   \n",
       "2  {1D9636EF-89D5-4C13-9576-38F86FF02784}      NaN         5154         789   \n",
       "3  {195B01BB-49D5-4D20-B1CD-9DA3ECBD5B59}    Zandt         5154         371   \n",
       "4  {43A29E44-F662-4FFB-A690-62E4D050948D}      NaN         5154         786   \n",
       "\n",
       "  nenner_csv            lage gemeinde_csv zaeh_nenn_csv Fläche [qm]:  \n",
       "0          0     Hohe Rieder       372177         794/0    24.345,41  \n",
       "1          1        Aufelder       372177         247/1     7.471,83  \n",
       "2          2     Ochsenweide       372177         789/2       482,88  \n",
       "3          6  Auf der Riesel       372177         371/6     5.167,59  \n",
       "4          0       Berghäusl       372177         786/0     4.309,08  \n",
       "\n",
       "[5 rows x 39 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# TEST: Manually check CSV merge for the first vector file\n",
    "if vector_files and csv_folder:\n",
    "    test_vector = vector_files[0]\n",
    "    print(f\"Testing with vector file: {os.path.basename(test_vector)}\")\n",
    "    print(f\"CSV folder: {csv_folder}\\n\")\n",
    "    \n",
    "    # Load shapefile\n",
    "    gdf_test = gpd.read_file(test_vector)\n",
    "    print(f\"1. Shapefile columns: {list(gdf_test.columns)}\")\n",
    "    print(f\"   Number of features: {len(gdf_test)}\")\n",
    "    if MERGE_KEY_COLUMN in gdf_test.columns:\n",
    "        print(f\"   '{MERGE_KEY_COLUMN}' values: {gdf_test[MERGE_KEY_COLUMN].tolist()}\")\n",
    "    print()\n",
    "    \n",
    "    # Look for CSV\n",
    "    vector_basename = Path(test_vector).stem\n",
    "    csv_test_path = os.path.join(csv_folder, f\"{vector_basename}.csv\")\n",
    "    print(f\"2. Looking for CSV: {csv_test_path}\")\n",
    "    print(f\"   CSV exists: {os.path.exists(csv_test_path)}\\n\")\n",
    "    \n",
    "    if os.path.exists(csv_test_path):\n",
    "        # Load CSV (try different encodings and separators for German CSV files)\n",
    "        csv_test = None\n",
    "        for encoding in ['utf-8', 'cp1252', 'iso-8859-1', 'latin1']:\n",
    "            for sep in [';', ',']:\n",
    "                try:\n",
    "                    csv_test = pd.read_csv(csv_test_path, encoding=encoding, sep=sep)\n",
    "                    # Check if it was parsed correctly (more than 1 column)\n",
    "                    if len(csv_test.columns) > 1:\n",
    "                        print(f\"3. CSV loaded successfully with encoding: {encoding}, separator: '{sep}'\")\n",
    "                        break\n",
    "                except (UnicodeDecodeError, Exception):\n",
    "                    continue\n",
    "            if csv_test is not None and len(csv_test.columns) > 1:\n",
    "                break\n",
    "        \n",
    "        if csv_test is None or len(csv_test.columns) <= 1:\n",
    "            print(\"   ✗ Could not read CSV with any standard encoding/separator\")\n",
    "        else:\n",
    "            print(f\"   CSV columns: {list(csv_test.columns)}\")\n",
    "            print(f\"   Number of rows: {len(csv_test)}\")\n",
    "            if MERGE_KEY_COLUMN in csv_test.columns:\n",
    "                print(f\"   '{MERGE_KEY_COLUMN}' values: {csv_test[MERGE_KEY_COLUMN].tolist()}\")\n",
    "            print(f\"\\n   CSV Preview:\")\n",
    "            display(csv_test.head())\n",
    "            \n",
    "            # Try merge\n",
    "            print(f\"\\n4. Attempting merge on '{MERGE_KEY_COLUMN}'...\")\n",
    "            if MERGE_KEY_COLUMN in gdf_test.columns and MERGE_KEY_COLUMN in csv_test.columns:\n",
    "                gdf_merged_test = gdf_test.merge(csv_test, on=MERGE_KEY_COLUMN, how='left', suffixes=('', '_csv'))\n",
    "                print(f\"   ✓ Merge successful!\")\n",
    "                print(f\"   Merged columns: {list(gdf_merged_test.columns)}\")\n",
    "                \n",
    "                # Check for 'lage'\n",
    "                if 'lage' in gdf_merged_test.columns:\n",
    "                    print(f\"\\n   ✓✓✓ 'lage' column is present!\")\n",
    "                    print(f\"   'lage' values: {gdf_merged_test['lage'].dropna().tolist()}\")\n",
    "                else:\n",
    "                    print(f\"\\n   ✗✗✗ 'lage' column NOT found after merge\")\n",
    "                \n",
    "                print(f\"\\n   Merged data preview:\")\n",
    "                display(gdf_merged_test[[col for col in gdf_merged_test.columns if col != 'geometry']].head())\n",
    "            else:\n",
    "                print(f\"   ✗ Merge key '{MERGE_KEY_COLUMN}' not found in both files\")\n",
    "    else:\n",
    "        print(f\"   ⚠ CSV file not found!\")\n",
    "        print(f\"\\n   Files in CSV folder:\")\n",
    "        if os.path.isdir(csv_folder):\n",
    "            csv_files = [f for f in os.listdir(csv_folder) if f.endswith('.csv')]\n",
    "            for f in csv_files:\n",
    "                print(f\"      - {f}\")\n",
    "else:\n",
    "    print(\"⚠ No vector files or CSV folder not configured\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "0fda30a7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading 1 vector file(s)...\n",
      "\n",
      "Vector File 1: Zandt.shp\n",
      "  CRS: EPSG:25832\n",
      "  Features: 9\n",
      "  Bounds: [ 770837.0501 5449162.8901  773254.2001 5453261.4201]\n",
      "  Columns: ['objectid', 'gemeinde', 'gmkgcode', 'zaehler', 'nenner', 'zaeh_nenn', 'afl', 'egtid', 'name_eigen', 'vorname', 'anrede', 'namensbest', 'akademisch', 'geburtsnam', 'geburtsdat', 'strassehau', 'plz', 'ort', 'herkunft', 'amtsgerich', 'grundbuchb', 'miteigentu', 'artrechtsg', 'anteileige', 'buchungsar', 'lfdnrbesta', 'flstkennz', 'gbbz', 'blatt', 'aelf_kurz', 'globalid', 'geometry']\n",
      "\n",
      "Preview of first vector file:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>objectid</th>\n",
       "      <th>gemeinde</th>\n",
       "      <th>gmkgcode</th>\n",
       "      <th>zaehler</th>\n",
       "      <th>nenner</th>\n",
       "      <th>zaeh_nenn</th>\n",
       "      <th>afl</th>\n",
       "      <th>egtid</th>\n",
       "      <th>name_eigen</th>\n",
       "      <th>vorname</th>\n",
       "      <th>...</th>\n",
       "      <th>artrechtsg</th>\n",
       "      <th>anteileige</th>\n",
       "      <th>buchungsar</th>\n",
       "      <th>lfdnrbesta</th>\n",
       "      <th>flstkennz</th>\n",
       "      <th>gbbz</th>\n",
       "      <th>blatt</th>\n",
       "      <th>aelf_kurz</th>\n",
       "      <th>globalid</th>\n",
       "      <th>geometry</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1158151</td>\n",
       "      <td>372177</td>\n",
       "      <td>5154</td>\n",
       "      <td>794</td>\n",
       "      <td>0</td>\n",
       "      <td>794/0</td>\n",
       "      <td>24170</td>\n",
       "      <td>095154_1210_1</td>\n",
       "      <td>Gemeinde Zandt</td>\n",
       "      <td>None</td>\n",
       "      <td>...</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>1100</td>\n",
       "      <td>208</td>\n",
       "      <td>095154___00794______</td>\n",
       "      <td>095154</td>\n",
       "      <td>1210</td>\n",
       "      <td>ch</td>\n",
       "      <td>{AF1ACD63-6327-49E9-A492-416D3BD5043E}</td>\n",
       "      <td>MULTIPOLYGON (((772924.97 5453020.18, 772929.9...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>5187721</td>\n",
       "      <td>372177</td>\n",
       "      <td>5154</td>\n",
       "      <td>247</td>\n",
       "      <td>1</td>\n",
       "      <td>247/1</td>\n",
       "      <td>7465</td>\n",
       "      <td>095154_1210_1</td>\n",
       "      <td>Gemeinde Zandt</td>\n",
       "      <td>None</td>\n",
       "      <td>...</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>1100</td>\n",
       "      <td>73</td>\n",
       "      <td>095154___002470001__</td>\n",
       "      <td>095154</td>\n",
       "      <td>1210</td>\n",
       "      <td>ch</td>\n",
       "      <td>{CE64DB4E-728A-4FBF-8821-59D7821819DA}</td>\n",
       "      <td>POLYGON ((770941.58 5451489.42, 770951.67 5451...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>7896069</td>\n",
       "      <td>372177</td>\n",
       "      <td>5154</td>\n",
       "      <td>789</td>\n",
       "      <td>2</td>\n",
       "      <td>789/2</td>\n",
       "      <td>480</td>\n",
       "      <td>095154_1210_1</td>\n",
       "      <td>Gemeinde Zandt</td>\n",
       "      <td>None</td>\n",
       "      <td>...</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>1100</td>\n",
       "      <td>399</td>\n",
       "      <td>095154___007890002__</td>\n",
       "      <td>095154</td>\n",
       "      <td>1210</td>\n",
       "      <td>ch</td>\n",
       "      <td>{1D9636EF-89D5-4C13-9576-38F86FF02784}</td>\n",
       "      <td>POLYGON ((773240.02 5452981.84, 773254.2 54529...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>13305024</td>\n",
       "      <td>372177</td>\n",
       "      <td>5154</td>\n",
       "      <td>371</td>\n",
       "      <td>6</td>\n",
       "      <td>371/6</td>\n",
       "      <td>5170</td>\n",
       "      <td>095154_1210_1</td>\n",
       "      <td>Gemeinde Zandt</td>\n",
       "      <td>None</td>\n",
       "      <td>...</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>1100</td>\n",
       "      <td>101</td>\n",
       "      <td>095154___003710006__</td>\n",
       "      <td>095154</td>\n",
       "      <td>1210</td>\n",
       "      <td>ch</td>\n",
       "      <td>{195B01BB-49D5-4D20-B1CD-9DA3ECBD5B59}</td>\n",
       "      <td>POLYGON ((771080.44 5450302.71, 771077.2 54503...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>13437600</td>\n",
       "      <td>372177</td>\n",
       "      <td>5154</td>\n",
       "      <td>786</td>\n",
       "      <td>0</td>\n",
       "      <td>786/0</td>\n",
       "      <td>4305</td>\n",
       "      <td>095154_1210_1</td>\n",
       "      <td>Gemeinde Zandt</td>\n",
       "      <td>None</td>\n",
       "      <td>...</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>1100</td>\n",
       "      <td>397</td>\n",
       "      <td>095154___00786______</td>\n",
       "      <td>095154</td>\n",
       "      <td>1210</td>\n",
       "      <td>ch</td>\n",
       "      <td>{43A29E44-F662-4FFB-A690-62E4D050948D}</td>\n",
       "      <td>POLYGON ((773147.05 5452892.57, 773169.77 5452...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 32 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   objectid  gemeinde  gmkgcode  zaehler  nenner zaeh_nenn    afl  \\\n",
       "0   1158151    372177      5154      794       0     794/0  24170   \n",
       "1   5187721    372177      5154      247       1     247/1   7465   \n",
       "2   7896069    372177      5154      789       2     789/2    480   \n",
       "3  13305024    372177      5154      371       6     371/6   5170   \n",
       "4  13437600    372177      5154      786       0     786/0   4305   \n",
       "\n",
       "           egtid      name_eigen vorname  ... artrechtsg anteileige  \\\n",
       "0  095154_1210_1  Gemeinde Zandt    None  ...       None       None   \n",
       "1  095154_1210_1  Gemeinde Zandt    None  ...       None       None   \n",
       "2  095154_1210_1  Gemeinde Zandt    None  ...       None       None   \n",
       "3  095154_1210_1  Gemeinde Zandt    None  ...       None       None   \n",
       "4  095154_1210_1  Gemeinde Zandt    None  ...       None       None   \n",
       "\n",
       "  buchungsar lfdnrbesta             flstkennz    gbbz blatt aelf_kurz  \\\n",
       "0       1100        208  095154___00794______  095154  1210        ch   \n",
       "1       1100         73  095154___002470001__  095154  1210        ch   \n",
       "2       1100        399  095154___007890002__  095154  1210        ch   \n",
       "3       1100        101  095154___003710006__  095154  1210        ch   \n",
       "4       1100        397  095154___00786______  095154  1210        ch   \n",
       "\n",
       "                                 globalid  \\\n",
       "0  {AF1ACD63-6327-49E9-A492-416D3BD5043E}   \n",
       "1  {CE64DB4E-728A-4FBF-8821-59D7821819DA}   \n",
       "2  {1D9636EF-89D5-4C13-9576-38F86FF02784}   \n",
       "3  {195B01BB-49D5-4D20-B1CD-9DA3ECBD5B59}   \n",
       "4  {43A29E44-F662-4FFB-A690-62E4D050948D}   \n",
       "\n",
       "                                            geometry  \n",
       "0  MULTIPOLYGON (((772924.97 5453020.18, 772929.9...  \n",
       "1  POLYGON ((770941.58 5451489.42, 770951.67 5451...  \n",
       "2  POLYGON ((773240.02 5452981.84, 773254.2 54529...  \n",
       "3  POLYGON ((771080.44 5450302.71, 771077.2 54503...  \n",
       "4  POLYGON ((773147.05 5452892.57, 773169.77 5452...  \n",
       "\n",
       "[5 rows x 32 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Load and inspect vector data\n",
    "if vector_files:\n",
    "    print(f\"Loading {len(vector_files)} vector file(s)...\\n\")\n",
    "    \n",
    "    for i, vf in enumerate(vector_files, 1):\n",
    "        print(f\"Vector File {i}: {os.path.basename(vf)}\")\n",
    "        gdf = gpd.read_file(vf)\n",
    "        print(f\"  CRS: {gdf.crs}\")\n",
    "        print(f\"  Features: {len(gdf)}\")\n",
    "        print(f\"  Bounds: {gdf.total_bounds}\")\n",
    "        print(f\"  Columns: {list(gdf.columns)}\\n\")\n",
    "    \n",
    "    # Show preview of first vector file\n",
    "    print(\"Preview of first vector file:\")\n",
    "    gdf_first = gpd.read_file(vector_files[0])\n",
    "    display(gdf_first.head())\n",
    "else:\n",
    "    print(\"⚠ No vector files found!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b01e6ffe",
   "metadata": {},
   "source": [
    "## 4. Quick Preview of One CHM\n",
    "\n",
    "Let's inspect the first CHM file to verify everything is working."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "156283d1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Preview of: 20250909_066_Zandt-13305024_M3E_CHM.tif\n",
      "\n",
      "CHM Raster Information:\n",
      "  CRS: EPSG:25832\n",
      "  Dimensions: 7830 x 7651\n",
      "  Bounds: BoundingBox(left=770901.6136531901, bottom=5450141.332445897, right=771284.596175752, top=5450515.559684738)\n",
      "  Resolution: (0.048912199560908476, 0.048912199560897075)\n",
      "  NoData value: -9999.0\n",
      "\n",
      "  Height range: -5.53 - 35.89 m\n",
      "  Mean height: 13.28 m\n",
      "  Valid pixels: 39,206,635 / 59,907,330 (65.4%)\n"
     ]
    }
   ],
   "source": [
    "if chm_files:\n",
    "    preview_chm = chm_files[0]\n",
    "    print(f\"Preview of: {os.path.basename(preview_chm)}\")\n",
    "    \n",
    "    with rasterio.open(preview_chm) as src:\n",
    "        print(f\"\\nCHM Raster Information:\")\n",
    "        print(f\"  CRS: {src.crs}\")\n",
    "        print(f\"  Dimensions: {src.width} x {src.height}\")\n",
    "        print(f\"  Bounds: {src.bounds}\")\n",
    "        print(f\"  Resolution: {src.res}\")\n",
    "        print(f\"  NoData value: {src.nodata}\")\n",
    "        \n",
    "        # Read and calculate statistics\n",
    "        chm_data = src.read(1, masked=True)\n",
    "        if hasattr(chm_data, 'filled'):\n",
    "            chm_data = np.where(chm_data.mask, np.nan, chm_data.data)\n",
    "        \n",
    "        valid_data = chm_data[~np.isnan(chm_data)]\n",
    "        print(f\"\\n  Height range: {np.min(valid_data):.2f} - {np.max(valid_data):.2f} m\")\n",
    "        print(f\"  Mean height: {np.mean(valid_data):.2f} m\")\n",
    "        print(f\"  Valid pixels: {len(valid_data):,} / {chm_data.size:,} ({len(valid_data)/chm_data.size*100:.1f}%)\")\n",
    "else:\n",
    "    print(\"No CHM files found!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d0781d8",
   "metadata": {},
   "source": [
    "## 5. Map Configuration (Same for All CHMs)\n",
    "\n",
    "Define the map styling that will be applied to all batch-generated maps."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "edaac50d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ Configuration loaded\n",
      "This configuration will be applied to all CHM files in the batch\n"
     ]
    }
   ],
   "source": [
    "# Map Element Configuration\n",
    "# This configuration will be used for ALL CHM files in the batch\n",
    "MAP_CONFIG = {\n",
    "    # ========== TEXT CONTENT (Change all text labels here!) ==========\n",
    "    'title': 'Baumhöhenkarte',           # Main title text (can be overridden per CHM)\n",
    "    'subtitle': '',                      # Will be set automatically from CHM filename\n",
    "    'legend_title': 'Legende',           # Legend title text\n",
    "    'legend_subtitle1': '',  # First line below legend title\n",
    "    'legend_subtitle2': 'Drohnenbefliegung 2025',  # Second line below legend title\n",
    "    'overview_label': 'Übersicht',       # Text below overview map\n",
    "    'location_name': 'Gemeinde Parsberg',  # Text above overview map\n",
    "    \n",
    "    # ========== TITLE AND SUBTITLE ==========\n",
    "    'title_fontsize': 16,\n",
    "    'subtitle_fontsize': 11,\n",
    "    'title_position_x': 0.82,\n",
    "    'title_position_y': 0.95,\n",
    "    'title_align': 'left',\n",
    "    \n",
    "    # ========== LEGEND ==========\n",
    "    'legend_fontsize': 8,\n",
    "    'legend_title_fontsize': 11,\n",
    "    'legend_subtitle_fontsize': 8,\n",
    "    'legend_ncol': 1,\n",
    "    'legend_position_x': 0.88,\n",
    "    'legend_position_y': 0.63,\n",
    "    'legend_loc': 'center',\n",
    "    \n",
    "    # Legend size controls\n",
    "    'legend_labelspacing': 0.8,\n",
    "    'legend_handlelength': 1.5,\n",
    "    'legend_handletextpad': 0.81,\n",
    "    'legend_columnspacing': 1.0,\n",
    "    'legend_border_linewidth': 0,\n",
    "    \n",
    "    # Custom background box for legend\n",
    "    'legend_background_box_x': 0.815,\n",
    "    'legend_background_box_y': 0.18,\n",
    "    'legend_background_box_width': 0.17,\n",
    "    'legend_background_box_height': 0.60,\n",
    "    'legend_background_box_linewidth': 1,\n",
    "    \n",
    "    # ========== NORTH ARROW ==========\n",
    "    'north_arrow_fontsize': 14,\n",
    "    'north_arrow_position_x': 0.97,\n",
    "    'north_arrow_position_y': 0.22,\n",
    "    'north_arrow_length': 0.015,\n",
    "    'north_arrow_width': 2,\n",
    "    'north_arrow_pad': 0.3,\n",
    "    \n",
    "    # ========== OVERVIEW/LOCATOR MAP ==========\n",
    "    'overview_position_x': 0.90,\n",
    "    'overview_position_y': 0.27,\n",
    "    'overview_width': 0.15,\n",
    "    'overview_height': 0.15,\n",
    "    'overview_fontsize': 7,\n",
    "    'overview_border_width': 0.8,\n",
    "    'overview_chm_box_width': 1.5,\n",
    "    \n",
    "    # Location name text\n",
    "    'location_fontsize': 10,\n",
    "    'location_y_offset': 0.005,\n",
    "    \n",
    "    # ========== SCALE BAR ==========\n",
    "    'scalebar_fontsize': 9,\n",
    "    'scalebar_height': 0.015,\n",
    "    'scalebar_length': 0.22,\n",
    "    'scalebar_location': 'lower right',\n",
    "    'scalebar_pad_x': 0.02,  # keep snug to lower-right\n",
    "    'scalebar_pad_y': 4,     # point gap between number and bar\n",
    "    \n",
    "    # ========== SCALE TEXT ==========\n",
    "    'scale_text_fontsize': 10,\n",
    "    'scale_text_position_x': 0.91,\n",
    "    'scale_text_position_y': 0.02,\n",
    "    'scale_text_align': 'left',\n",
    "    \n",
    "    # ========== VISUAL STYLING ==========\n",
    "    'vector_linewidth': 1.5,\n",
    "    'border_linewidth': 0,\n",
    "    \n",
    "    # ========== MAP POSITION ON PAGE ==========\n",
    "    'map_left': 0.02,\n",
    "    'map_right': 0.8,\n",
    "    'map_top': 0.98,\n",
    "    'map_bottom': 0.02,\n",
    "    \n",
    "    # ========== DEBUGGING ==========\n",
    "    'show_box_border': True\n",
    "}\n",
    "\n",
    "print(\"✓ Configuration loaded\")\n",
    "print(\"This configuration will be applied to all CHM files in the batch\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c545d2b",
   "metadata": {},
   "source": [
    "## 6. Batch Processing Function\n",
    "\n",
    "This function processes each CHM file and generates a map."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "409963d9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ Batch processing function defined (with duplicate filename handling)\n"
     ]
    }
   ],
   "source": [
    "def load_and_merge_vector_csv(vector_path, csv_folder, merge_key):\n",
    "    \"\"\"\n",
    "    Load vector file and merge with CSV data if available.\n",
    "    \"\"\"\n",
    "    gdf = gpd.read_file(vector_path)\n",
    "    print(f\"       Vector columns before merge: {list(gdf.columns)}\")\n",
    "    \n",
    "    if csv_folder is None or not os.path.isdir(csv_folder):\n",
    "        return gdf\n",
    "    \n",
    "    vector_basename = Path(vector_path).stem\n",
    "    csv_path = os.path.join(csv_folder, f\"{vector_basename}.csv\")\n",
    "    \n",
    "    if not os.path.exists(csv_path):\n",
    "        print(f\"       No CSV file found at: {csv_path}\")\n",
    "        return gdf\n",
    "    \n",
    "    try:\n",
    "        csv_df = None\n",
    "        for encoding in ['utf-8', 'cp1252', 'iso-8859-1', 'latin1']:\n",
    "            for sep in [';', ',']:\n",
    "                try:\n",
    "                    csv_df = pd.read_csv(csv_path, encoding=encoding, sep=sep)\n",
    "                    if len(csv_df.columns) > 1:\n",
    "                        print(f\"       ✓ Found matching CSV: {os.path.basename(csv_path)} (encoding: {encoding}, separator: '{sep}')\")\n",
    "                        break\n",
    "                except (UnicodeDecodeError, Exception):\n",
    "                    continue\n",
    "            if csv_df is not None and len(csv_df.columns) > 1:\n",
    "                break\n",
    "        \n",
    "        if csv_df is None or len(csv_df.columns) <= 1:\n",
    "            print(f\"       ⚠ Warning: Could not read CSV. Skipping merge.\")\n",
    "            return gdf\n",
    "        \n",
    "        print(f\"       CSV columns: {list(csv_df.columns)}\")\n",
    "        \n",
    "        if merge_key not in gdf.columns:\n",
    "            print(f\"       ⚠ Warning: Merge key '{merge_key}' not found in shapefile.\")\n",
    "            return gdf\n",
    "        \n",
    "        if merge_key not in csv_df.columns:\n",
    "            print(f\"       ⚠ Warning: Merge key '{merge_key}' not found in CSV.\")\n",
    "            return gdf\n",
    "        \n",
    "        gdf_merged = gdf.merge(csv_df, on=merge_key, how='left', suffixes=('', '_csv'))\n",
    "        merged_count = gdf_merged[merge_key].notna().sum()\n",
    "        print(f\"       ✓ Merged CSV data: {merged_count} features matched on '{merge_key}'\")\n",
    "        \n",
    "        if 'lage' in gdf_merged.columns:\n",
    "            lage_values = gdf_merged['lage'].dropna().unique()\n",
    "            print(f\"       'lage' unique values (raw): {lage_values}\")\n",
    "        \n",
    "        return gdf_merged\n",
    "    \n",
    "    except Exception as e:\n",
    "        print(f\"       ⚠ Error merging CSV: {e}\")\n",
    "        return gdf\n",
    "\n",
    "\n",
    "def get_unique_filename(base_filename, used_filenames):\n",
    "    \"\"\"\n",
    "    Generate a unique filename by adding _2, _3, etc. suffix if needed.\n",
    "    \"\"\"\n",
    "    if base_filename not in used_filenames:\n",
    "        used_filenames[base_filename] = 1\n",
    "        return base_filename\n",
    "    else:\n",
    "        used_filenames[base_filename] += 1\n",
    "        count = used_filenames[base_filename]\n",
    "        return f\"{base_filename}_{count}\"\n",
    "\n",
    "\n",
    "def get_valid_field_values(gdf, field_name):\n",
    "    \"\"\"\n",
    "    Get valid (non-empty, non-whitespace) values from a GeoDataFrame column.\n",
    "    Returns list of valid string values.\n",
    "    \"\"\"\n",
    "    if field_name not in gdf.columns:\n",
    "        return []\n",
    "    \n",
    "    values = gdf[field_name].dropna().unique()\n",
    "    valid_values = []\n",
    "    for v in values:\n",
    "        str_val = str(v).strip()\n",
    "        # Check if it's valid: non-empty, not 'nan', not 'none', not just whitespace\n",
    "        if str_val and str_val.lower() not in ('nan', 'none', 'null', ''):\n",
    "            valid_values.append(str_val)\n",
    "    \n",
    "    return valid_values\n",
    "\n",
    "\n",
    "def process_single_chm(chm_path, vector_files, output_dir, config, csv_folder=None, \n",
    "                       merge_key=\"afl\", use_custom_subtitle=True, field1=\"ort\", \n",
    "                       field2=\"lage\", location_field=\"name_eigen\", clip_to_shapes=False, \n",
    "                       clip_buffer=10, index=None, total=None, used_filenames=None):\n",
    "    \"\"\"\n",
    "    Process a single CHM file and generate a PDF map.\n",
    "    \"\"\"\n",
    "    if used_filenames is None:\n",
    "        used_filenames = {}\n",
    "    \n",
    "    try:\n",
    "        chm_filename = Path(chm_path).stem\n",
    "        \n",
    "        if index and total:\n",
    "            print(f\"\\n{'='*80}\")\n",
    "            print(f\"Processing [{index}/{total}]: {chm_filename}\")\n",
    "            print(f\"{'='*80}\")\n",
    "        else:\n",
    "            print(f\"\\nProcessing: {chm_filename}\")\n",
    "        \n",
    "        if isinstance(vector_files, str):\n",
    "            vector_files_list = [vector_files]\n",
    "        else:\n",
    "            vector_files_list = vector_files\n",
    "        \n",
    "        print(f\"  1. Checking {len(vector_files_list)} vector file(s) for overlap...\")\n",
    "        with rasterio.open(chm_path) as src:\n",
    "            chm_bounds = src.bounds\n",
    "            chm_crs = src.crs\n",
    "        \n",
    "        all_overlapping_gdfs = []\n",
    "        matching_vector_files = []\n",
    "        \n",
    "        for vf in vector_files_list:\n",
    "            gdf = load_and_merge_vector_csv(vf, csv_folder, merge_key)\n",
    "            \n",
    "            if gdf.crs != chm_crs:\n",
    "                gdf_reprojected = gdf.to_crs(chm_crs)\n",
    "            else:\n",
    "                gdf_reprojected = gdf\n",
    "            \n",
    "            overlapping_indices = []\n",
    "            for idx, geom in enumerate(gdf_reprojected.geometry):\n",
    "                geom_bounds = geom.bounds\n",
    "                overlaps = not (geom_bounds[2] < chm_bounds.left or \n",
    "                               geom_bounds[0] > chm_bounds.right or\n",
    "                               geom_bounds[3] < chm_bounds.bottom or \n",
    "                               geom_bounds[1] > chm_bounds.top)\n",
    "                if overlaps:\n",
    "                    overlapping_indices.append(idx)\n",
    "            \n",
    "            if overlapping_indices:\n",
    "                overlapping_gdf = gdf_reprojected.iloc[overlapping_indices].copy()\n",
    "                all_overlapping_gdfs.append(overlapping_gdf)\n",
    "                matching_vector_files.append(vf)\n",
    "                print(f\"     ✓ {os.path.basename(vf)}: {len(overlapping_indices)} geometry(ies)\")\n",
    "        \n",
    "        if not all_overlapping_gdfs:\n",
    "            print(\"  ⚠ Warning: No overlapping vectors found for this CHM. Skipping.\")\n",
    "            return None\n",
    "        \n",
    "        combined_gdf = gpd.GeoDataFrame(pd.concat(all_overlapping_gdfs, ignore_index=True))\n",
    "        print(f\"  Total overlapping geometries: {len(combined_gdf)}\")\n",
    "        \n",
    "        print(\"  2. Loading CHM data...\")\n",
    "        vector_path_for_init = matching_vector_files[0]\n",
    "        mapper = CHMMapper(chm_path, vector_path_for_init)\n",
    "        mapper.load_data()\n",
    "        \n",
    "        if clip_to_shapes:\n",
    "            try:\n",
    "                buffered_geoms = combined_gdf.geometry.buffer(clip_buffer)\n",
    "                shapes = [geom.__geo_interface__ for geom in buffered_geoms if not geom.is_empty]\n",
    "                if shapes:\n",
    "                    print(f\"  3b. Clipping CHM to shapes (+{clip_buffer} m buffer)...\")\n",
    "                    with rasterio.open(chm_path) as src:\n",
    "                        clipped_data, clipped_transform = mask(src, shapes, crop=True, nodata=src.nodata)\n",
    "                    mapper.chm_data = clipped_data[0]\n",
    "                    mapper.chm_transform = clipped_transform\n",
    "                    bounds = array_bounds(mapper.chm_data.shape[0], mapper.chm_data.shape[1], clipped_transform)\n",
    "                    mapper.chm_bounds = rasterio.coords.BoundingBox(*bounds)\n",
    "            except Exception as e:\n",
    "                print(f\"  ⚠ Clip failed ({e}); using full CHM.\")\n",
    "        \n",
    "        print(f\"  3. Using combined geometries from {len(matching_vector_files)} vector file(s)...\")\n",
    "        mapper.vector_gdf = combined_gdf\n",
    "        \n",
    "        chm_config = config.copy()\n",
    "        \n",
    "        # Extract location_name\n",
    "        if location_field in combined_gdf.columns:\n",
    "            location_values = get_valid_field_values(combined_gdf, location_field)\n",
    "            if location_values:\n",
    "                chm_config['location_name'] = location_values[0]\n",
    "                print(f\"  Location: {chm_config['location_name']}\")\n",
    "        \n",
    "        # Create subtitle and filename\n",
    "        subtitle_for_filename = None\n",
    "        if use_custom_subtitle:\n",
    "            try:\n",
    "                subtitle_parts = []\n",
    "                has_field1 = field1 in combined_gdf.columns\n",
    "                has_field2 = field2 in combined_gdf.columns\n",
    "                \n",
    "                print(f\"  Checking subtitle fields: field1='{field1}' (exists: {has_field1}), field2='{field2}' (exists: {has_field2})\")\n",
    "                \n",
    "                if has_field1 or has_field2:\n",
    "                    if has_field1:\n",
    "                        field1_values = get_valid_field_values(combined_gdf, field1)\n",
    "                        if len(field1_values) == 1:\n",
    "                            subtitle_parts.append(field1_values[0])\n",
    "                        elif len(field1_values) > 1:\n",
    "                            subtitle_parts.extend(sorted(field1_values))\n",
    "                    \n",
    "                    if has_field2:\n",
    "                        field2_values = get_valid_field_values(combined_gdf, field2)\n",
    "                        print(f\"  field2 ('{field2}') valid values: {field2_values}\")\n",
    "                        if field2_values:\n",
    "                            sorted_field2 = sorted(field2_values)\n",
    "                            if len(sorted_field2) > 4:\n",
    "                                subtitle_parts.extend(sorted_field2[:4])\n",
    "                                subtitle_parts.append('...')\n",
    "                            else:\n",
    "                                subtitle_parts.extend(sorted_field2)\n",
    "                        else:\n",
    "                            # FALLBACK: use merge_key (afl) instead of field2 (lage)\n",
    "                            print(f\"  ⚠ No valid '{field2}' values. Falling back to '{merge_key}'...\")\n",
    "                            fallback_values = get_valid_field_values(combined_gdf, merge_key)\n",
    "                            if fallback_values:\n",
    "                                sorted_fallback = sorted(fallback_values)\n",
    "                                if len(sorted_fallback) > 4:\n",
    "                                    subtitle_parts.extend(sorted_fallback[:4])\n",
    "                                    subtitle_parts.append('...')\n",
    "                                else:\n",
    "                                    subtitle_parts.extend(sorted_fallback)\n",
    "                                print(f\"  Using '{merge_key}' values: {fallback_values}\")\n",
    "                    \n",
    "                    if subtitle_parts:\n",
    "                        subtitle = \"_\".join(subtitle_parts)\n",
    "                        chm_config['subtitle'] = subtitle\n",
    "                        subtitle_for_filename = subtitle\n",
    "                        print(f\"  Subtitle: {subtitle}\")\n",
    "                    else:\n",
    "                        chm_config['subtitle'] = chm_filename\n",
    "                        subtitle_for_filename = chm_filename\n",
    "                        print(f\"  ⚠ No valid values in '{field1}'/'{field2}'. Using CHM filename.\")\n",
    "                else:\n",
    "                    chm_config['subtitle'] = chm_filename\n",
    "                    subtitle_for_filename = chm_filename\n",
    "                    print(f\"  ⚠ Fields not found. Using CHM filename.\")\n",
    "            except Exception as e:\n",
    "                chm_config['subtitle'] = chm_filename\n",
    "                subtitle_for_filename = chm_filename\n",
    "                print(f\"  ⚠ Error creating subtitle: {e}. Using CHM filename.\")\n",
    "        else:\n",
    "            chm_config['subtitle'] = chm_filename\n",
    "            subtitle_for_filename = chm_filename\n",
    "        \n",
    "        # Create unique filename (avoid overwriting)\n",
    "        print(\"  4. Creating map...\")\n",
    "        base_filename = f\"Baumhoehenkarte_{subtitle_for_filename}\"\n",
    "        unique_filename = get_unique_filename(base_filename, used_filenames)\n",
    "        \n",
    "        if unique_filename != base_filename:\n",
    "            print(f\"  ⚠ Filename '{base_filename}.pdf' already used, using '{unique_filename}.pdf' instead.\")\n",
    "        \n",
    "        output_filename = f\"{unique_filename}.pdf\"\n",
    "        output_path = os.path.join(output_dir, output_filename)\n",
    "        \n",
    "        mapper.create_map(\n",
    "            data=mapper.chm_data,\n",
    "            transform=mapper.chm_transform,\n",
    "            bounds=mapper.chm_bounds,\n",
    "            output_path=output_path,\n",
    "            figsize=(16.53, 11.69),\n",
    "            dpi=300,\n",
    "            add_overview=True,\n",
    "            config=chm_config\n",
    "        )\n",
    "        \n",
    "        print(f\"  ✓ Success! Saved to: {output_path}\")\n",
    "        return True\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"  ✗ Error processing {chm_filename}: {str(e)}\")\n",
    "        import traceback\n",
    "        traceback.print_exc()\n",
    "        return False\n",
    "\n",
    "print(\"✓ Batch processing function defined (with duplicate filename handling)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b963b6a",
   "metadata": {},
   "source": [
    "## 7. Run Batch Processing\n",
    "\n",
    "Process all CHM files and generate PDF maps."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "13583ca5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "================================================================================\n",
      "BATCH PROCESSING STARTED\n",
      "Total CHM files to process: 5\n",
      "Total vector files available: 1\n",
      "CSV folder: D:\\Drohnendaten\\15_FESMART\\01_Daten\\06_AELF-Cham\\00_Planung\\Info\n",
      "Merge key column: 'afl'\n",
      "Location field: 'name_eigen'\n",
      "Clip to shapes: True (buffer 30 m)\n",
      "Subtitle format: '_lage1_lage2_...'\n",
      "Output directory: D:\\Drohnendaten\\15_FESMART\\01_Daten\\06_AELF-Cham\\03_Mapping_output\\Zandt\n",
      "================================================================================\n",
      "\n",
      "================================================================================\n",
      "Processing [1/5]: 20250909_066_Zandt-13305024_M3E_CHM\n",
      "================================================================================\n",
      "  1. Checking 1 vector file(s) for overlap...\n",
      "       Vector columns before merge: ['objectid', 'gemeinde', 'gmkgcode', 'zaehler', 'nenner', 'zaeh_nenn', 'afl', 'egtid', 'name_eigen', 'vorname', 'anrede', 'namensbest', 'akademisch', 'geburtsnam', 'geburtsdat', 'strassehau', 'plz', 'ort', 'herkunft', 'amtsgerich', 'grundbuchb', 'miteigentu', 'artrechtsg', 'anteileige', 'buchungsar', 'lfdnrbesta', 'flstkennz', 'gbbz', 'blatt', 'aelf_kurz', 'globalid', 'geometry']\n",
      "       ✓ Found matching CSV: Zandt.csv (encoding: cp1252, separator: ';')\n",
      "       CSV columns: ['Gemeinde', 'gmkgcode', 'zaehler', 'nenner', 'afl', 'lage', 'gemeinde', 'zaeh_nenn', 'Fläche [qm]:']\n",
      "       ✓ Merged CSV data: 9 features matched on 'afl'\n",
      "       'lage' unique values (raw): ['Hohe Rieder' 'Aufelder' 'Ochsenweide' 'Auf der Riesel' 'Berghäusl'\n",
      " 'Auholz' 'Pfahlholz']\n",
      "     ✓ Zandt.shp: 1 geometry(ies)\n",
      "  Total overlapping geometries: 1\n",
      "  2. Loading CHM data...\n",
      "  Vector CRS: EPSG:25832\n",
      "  CHM CRS: EPSG:25832\n",
      "  → CRS match, no reprojection needed\n",
      "  3b. Clipping CHM to shapes (+30 m buffer)...\n",
      "  3. Using combined geometries from 1 vector file(s)...\n",
      "  Location: Gemeinde Zandt\n",
      "  Checking subtitle fields: field1='' (exists: False), field2='lage' (exists: True)\n",
      "  field2 ('lage') valid values: ['Auf der Riesel']\n",
      "  Subtitle: Auf der Riesel\n",
      "  4. Creating map...\n",
      "GeoPDF saved to: D:\\Drohnendaten\\15_FESMART\\01_Daten\\06_AELF-Cham\\03_Mapping_output\\Zandt\\Baumhoehenkarte_Auf der Riesel_geo.pdf\n",
      "  ✓ Success! Saved to: D:\\Drohnendaten\\15_FESMART\\01_Daten\\06_AELF-Cham\\03_Mapping_output\\Zandt\\Baumhoehenkarte_Auf der Riesel.pdf\n",
      "\n",
      "================================================================================\n",
      "Processing [2/5]: 20250909_067_Zandt-17655713_M3E_CHM\n",
      "================================================================================\n",
      "  1. Checking 1 vector file(s) for overlap...\n",
      "       Vector columns before merge: ['objectid', 'gemeinde', 'gmkgcode', 'zaehler', 'nenner', 'zaeh_nenn', 'afl', 'egtid', 'name_eigen', 'vorname', 'anrede', 'namensbest', 'akademisch', 'geburtsnam', 'geburtsdat', 'strassehau', 'plz', 'ort', 'herkunft', 'amtsgerich', 'grundbuchb', 'miteigentu', 'artrechtsg', 'anteileige', 'buchungsar', 'lfdnrbesta', 'flstkennz', 'gbbz', 'blatt', 'aelf_kurz', 'globalid', 'geometry']\n",
      "       ✓ Found matching CSV: Zandt.csv (encoding: cp1252, separator: ';')\n",
      "       CSV columns: ['Gemeinde', 'gmkgcode', 'zaehler', 'nenner', 'afl', 'lage', 'gemeinde', 'zaeh_nenn', 'Fläche [qm]:']\n",
      "       ✓ Merged CSV data: 9 features matched on 'afl'\n",
      "       'lage' unique values (raw): ['Hohe Rieder' 'Aufelder' 'Ochsenweide' 'Auf der Riesel' 'Berghäusl'\n",
      " 'Auholz' 'Pfahlholz']\n",
      "     ✓ Zandt.shp: 1 geometry(ies)\n",
      "  Total overlapping geometries: 1\n",
      "  2. Loading CHM data...\n",
      "  Vector CRS: EPSG:25832\n",
      "  CHM CRS: EPSG:25832\n",
      "  → CRS match, no reprojection needed\n",
      "  3b. Clipping CHM to shapes (+30 m buffer)...\n",
      "  3. Using combined geometries from 1 vector file(s)...\n",
      "  Location: Gemeinde Zandt\n",
      "  Checking subtitle fields: field1='' (exists: False), field2='lage' (exists: True)\n",
      "  field2 ('lage') valid values: ['Pfahlholz']\n",
      "  Subtitle: Pfahlholz\n",
      "  4. Creating map...\n",
      "GeoPDF saved to: D:\\Drohnendaten\\15_FESMART\\01_Daten\\06_AELF-Cham\\03_Mapping_output\\Zandt\\Baumhoehenkarte_Pfahlholz_geo.pdf\n",
      "  ✓ Success! Saved to: D:\\Drohnendaten\\15_FESMART\\01_Daten\\06_AELF-Cham\\03_Mapping_output\\Zandt\\Baumhoehenkarte_Pfahlholz.pdf\n",
      "\n",
      "================================================================================\n",
      "Processing [3/5]: 20250909_068_Zandt-5187721_M3E_CHM\n",
      "================================================================================\n",
      "  1. Checking 1 vector file(s) for overlap...\n",
      "       Vector columns before merge: ['objectid', 'gemeinde', 'gmkgcode', 'zaehler', 'nenner', 'zaeh_nenn', 'afl', 'egtid', 'name_eigen', 'vorname', 'anrede', 'namensbest', 'akademisch', 'geburtsnam', 'geburtsdat', 'strassehau', 'plz', 'ort', 'herkunft', 'amtsgerich', 'grundbuchb', 'miteigentu', 'artrechtsg', 'anteileige', 'buchungsar', 'lfdnrbesta', 'flstkennz', 'gbbz', 'blatt', 'aelf_kurz', 'globalid', 'geometry']\n",
      "       ✓ Found matching CSV: Zandt.csv (encoding: cp1252, separator: ';')\n",
      "       CSV columns: ['Gemeinde', 'gmkgcode', 'zaehler', 'nenner', 'afl', 'lage', 'gemeinde', 'zaeh_nenn', 'Fläche [qm]:']\n",
      "       ✓ Merged CSV data: 9 features matched on 'afl'\n",
      "       'lage' unique values (raw): ['Hohe Rieder' 'Aufelder' 'Ochsenweide' 'Auf der Riesel' 'Berghäusl'\n",
      " 'Auholz' 'Pfahlholz']\n",
      "     ✓ Zandt.shp: 1 geometry(ies)\n",
      "  Total overlapping geometries: 1\n",
      "  2. Loading CHM data...\n",
      "  Vector CRS: EPSG:25832\n",
      "  CHM CRS: EPSG:25832\n",
      "  → CRS match, no reprojection needed\n",
      "  3b. Clipping CHM to shapes (+30 m buffer)...\n",
      "  3. Using combined geometries from 1 vector file(s)...\n",
      "  Location: Gemeinde Zandt\n",
      "  Checking subtitle fields: field1='' (exists: False), field2='lage' (exists: True)\n",
      "  field2 ('lage') valid values: ['Aufelder']\n",
      "  Subtitle: Aufelder\n",
      "  4. Creating map...\n",
      "GeoPDF saved to: D:\\Drohnendaten\\15_FESMART\\01_Daten\\06_AELF-Cham\\03_Mapping_output\\Zandt\\Baumhoehenkarte_Aufelder_geo.pdf\n",
      "  ✓ Success! Saved to: D:\\Drohnendaten\\15_FESMART\\01_Daten\\06_AELF-Cham\\03_Mapping_output\\Zandt\\Baumhoehenkarte_Aufelder.pdf\n",
      "\n",
      "================================================================================\n",
      "Processing [4/5]: 20250909_069_Zandt-14027838_M3E_CHM\n",
      "================================================================================\n",
      "  1. Checking 1 vector file(s) for overlap...\n",
      "       Vector columns before merge: ['objectid', 'gemeinde', 'gmkgcode', 'zaehler', 'nenner', 'zaeh_nenn', 'afl', 'egtid', 'name_eigen', 'vorname', 'anrede', 'namensbest', 'akademisch', 'geburtsnam', 'geburtsdat', 'strassehau', 'plz', 'ort', 'herkunft', 'amtsgerich', 'grundbuchb', 'miteigentu', 'artrechtsg', 'anteileige', 'buchungsar', 'lfdnrbesta', 'flstkennz', 'gbbz', 'blatt', 'aelf_kurz', 'globalid', 'geometry']\n",
      "       ✓ Found matching CSV: Zandt.csv (encoding: cp1252, separator: ';')\n",
      "       CSV columns: ['Gemeinde', 'gmkgcode', 'zaehler', 'nenner', 'afl', 'lage', 'gemeinde', 'zaeh_nenn', 'Fläche [qm]:']\n",
      "       ✓ Merged CSV data: 9 features matched on 'afl'\n",
      "       'lage' unique values (raw): ['Hohe Rieder' 'Aufelder' 'Ochsenweide' 'Auf der Riesel' 'Berghäusl'\n",
      " 'Auholz' 'Pfahlholz']\n",
      "     ✓ Zandt.shp: 1 geometry(ies)\n",
      "  Total overlapping geometries: 1\n",
      "  2. Loading CHM data...\n",
      "  Vector CRS: EPSG:25832\n",
      "  CHM CRS: EPSG:25832\n",
      "  → CRS match, no reprojection needed\n",
      "  3b. Clipping CHM to shapes (+30 m buffer)...\n",
      "  3. Using combined geometries from 1 vector file(s)...\n",
      "  Location: Gemeinde Zandt\n",
      "  Checking subtitle fields: field1='' (exists: False), field2='lage' (exists: True)\n",
      "  field2 ('lage') valid values: ['Auholz']\n",
      "  Subtitle: Auholz\n",
      "  4. Creating map...\n",
      "GeoPDF saved to: D:\\Drohnendaten\\15_FESMART\\01_Daten\\06_AELF-Cham\\03_Mapping_output\\Zandt\\Baumhoehenkarte_Auholz_geo.pdf\n",
      "  ✓ Success! Saved to: D:\\Drohnendaten\\15_FESMART\\01_Daten\\06_AELF-Cham\\03_Mapping_output\\Zandt\\Baumhoehenkarte_Auholz.pdf\n",
      "\n",
      "================================================================================\n",
      "Processing [5/5]: 20250909_070_Zandt-1158151_M3E_CHM\n",
      "================================================================================\n",
      "  1. Checking 1 vector file(s) for overlap...\n",
      "       Vector columns before merge: ['objectid', 'gemeinde', 'gmkgcode', 'zaehler', 'nenner', 'zaeh_nenn', 'afl', 'egtid', 'name_eigen', 'vorname', 'anrede', 'namensbest', 'akademisch', 'geburtsnam', 'geburtsdat', 'strassehau', 'plz', 'ort', 'herkunft', 'amtsgerich', 'grundbuchb', 'miteigentu', 'artrechtsg', 'anteileige', 'buchungsar', 'lfdnrbesta', 'flstkennz', 'gbbz', 'blatt', 'aelf_kurz', 'globalid', 'geometry']\n",
      "       ✓ Found matching CSV: Zandt.csv (encoding: cp1252, separator: ';')\n",
      "       CSV columns: ['Gemeinde', 'gmkgcode', 'zaehler', 'nenner', 'afl', 'lage', 'gemeinde', 'zaeh_nenn', 'Fläche [qm]:']\n",
      "       ✓ Merged CSV data: 9 features matched on 'afl'\n",
      "       'lage' unique values (raw): ['Hohe Rieder' 'Aufelder' 'Ochsenweide' 'Auf der Riesel' 'Berghäusl'\n",
      " 'Auholz' 'Pfahlholz']\n",
      "     ✓ Zandt.shp: 5 geometry(ies)\n",
      "  Total overlapping geometries: 5\n",
      "  2. Loading CHM data...\n",
      "  Vector CRS: EPSG:25832\n",
      "  CHM CRS: EPSG:25832\n",
      "  → CRS match, no reprojection needed\n",
      "  3b. Clipping CHM to shapes (+30 m buffer)...\n",
      "  3. Using combined geometries from 1 vector file(s)...\n",
      "  Location: Gemeinde Zandt\n",
      "  Checking subtitle fields: field1='' (exists: False), field2='lage' (exists: True)\n",
      "  field2 ('lage') valid values: ['Hohe Rieder', 'Ochsenweide', 'Berghäusl']\n",
      "  Subtitle: Berghäusl_Hohe Rieder_Ochsenweide\n",
      "  4. Creating map...\n",
      "GeoPDF saved to: D:\\Drohnendaten\\15_FESMART\\01_Daten\\06_AELF-Cham\\03_Mapping_output\\Zandt\\Baumhoehenkarte_Berghäusl_Hohe Rieder_Ochsenweide_geo.pdf\n",
      "  ✓ Success! Saved to: D:\\Drohnendaten\\15_FESMART\\01_Daten\\06_AELF-Cham\\03_Mapping_output\\Zandt\\Baumhoehenkarte_Berghäusl_Hohe Rieder_Ochsenweide.pdf\n",
      "\n",
      "================================================================================\n",
      "BATCH PROCESSING COMPLETED\n",
      "================================================================================\n",
      "Total files processed: 5\n",
      "  ✓ Successful: 5\n",
      "  ⚠ Skipped (no overlap): 0\n",
      "  ✗ Failed: 0\n",
      "\n",
      "Duration: 0:02:44.532637\n",
      "Average time per file: 0:00:32.906527\n",
      "\n",
      "Output directory: D:\\Drohnendaten\\15_FESMART\\01_Daten\\06_AELF-Cham\\03_Mapping_output\\Zandt\n"
     ]
    }
   ],
   "source": [
    "# Run batch processing\n",
    "print(f\"\\n\" + \"=\"*80)\n",
    "print(f\"BATCH PROCESSING STARTED\")\n",
    "print(f\"Total CHM files to process: {len(chm_files)}\")\n",
    "print(f\"Total vector files available: {len(vector_files)}\")\n",
    "print(f\"CSV folder: {csv_folder if csv_folder else 'None (not used)'}\")\n",
    "print(f\"Merge key column: '{MERGE_KEY_COLUMN}'\")\n",
    "print(f\"Location field: '{LOCATION_FIELD}'\")\n",
    "print(f\"Clip to shapes: {CLIP_TO_SHAPES} (buffer {CLIP_BUFFER_METERS} m)\")\n",
    "if SUBTITLE_USE_CUSTOM_FORMAT:\n",
    "    print(f\"Subtitle format: '{SUBTITLE_FIELD1}_{SUBTITLE_FIELD2}1_{SUBTITLE_FIELD2}2_...'\")\n",
    "else:\n",
    "    print(f\"Subtitle format: CHM filename\")\n",
    "print(f\"Output directory: {output_dir}\")\n",
    "print(f\"=\"*80)\n",
    "\n",
    "start_time = datetime.now()\n",
    "success_count = 0\n",
    "failed_count = 0\n",
    "skipped_count = 0\n",
    "\n",
    "# Track used filenames to avoid duplicates (shared across all CHM files)\n",
    "used_filenames = {}\n",
    "\n",
    "# Process each CHM file\n",
    "for i, chm_file in enumerate(chm_files, 1):\n",
    "    result = process_single_chm(\n",
    "        chm_path=chm_file,\n",
    "        vector_files=vector_files,\n",
    "        output_dir=output_dir,\n",
    "        config=MAP_CONFIG,\n",
    "        csv_folder=csv_folder,\n",
    "        merge_key=MERGE_KEY_COLUMN,\n",
    "        use_custom_subtitle=SUBTITLE_USE_CUSTOM_FORMAT,\n",
    "        field1=SUBTITLE_FIELD1,\n",
    "        field2=SUBTITLE_FIELD2,\n",
    "        location_field=LOCATION_FIELD,\n",
    "        clip_to_shapes=CLIP_TO_SHAPES,\n",
    "        clip_buffer=CLIP_BUFFER_METERS,\n",
    "        index=i,\n",
    "        total=len(chm_files),\n",
    "        used_filenames=used_filenames  # Pass shared dict to track duplicates\n",
    "    )\n",
    "    \n",
    "    if result is True:\n",
    "        success_count += 1\n",
    "    elif result is None:\n",
    "        skipped_count += 1\n",
    "    else:\n",
    "        failed_count += 1\n",
    "\n",
    "# Summary\n",
    "end_time = datetime.now()\n",
    "duration = end_time - start_time\n",
    "\n",
    "print(f\"\\n\" + \"=\"*80)\n",
    "print(f\"BATCH PROCESSING COMPLETED\")\n",
    "print(f\"=\"*80)\n",
    "print(f\"Total files processed: {len(chm_files)}\")\n",
    "print(f\"  ✓ Successful: {success_count}\")\n",
    "print(f\"  ⚠ Skipped (no overlap): {skipped_count}\")\n",
    "print(f\"  ✗ Failed: {failed_count}\")\n",
    "print(f\"\\nDuration: {duration}\")\n",
    "print(f\"Average time per file: {duration / len(chm_files) if chm_files else 0}\")\n",
    "print(f\"\\nOutput directory: {output_dir}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9df41f3d",
   "metadata": {},
   "source": [
    "## 8. List Generated Maps\n",
    "\n",
    "Show all the PDF files that were created."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "id": "4c7875b9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated PDF maps (5 files):\n",
      "\n",
      "  1. Baumhoehenkarte_Auf der Riesel_geo.pdf (0.60 MB)\n",
      "  2. Baumhoehenkarte_Aufelder_geo.pdf (0.38 MB)\n",
      "  3. Baumhoehenkarte_Auholz_geo.pdf (0.57 MB)\n",
      "  4. Baumhoehenkarte_Berghäusl_Hohe Rieder_Ochsenweide_geo.pdf (0.53 MB)\n",
      "  5. Baumhoehenkarte_Pfahlholz_geo.pdf (0.52 MB)\n",
      "\n",
      "✓ All maps saved in: D:\\Drohnendaten\\15_FESMART\\01_Daten\\06_AELF-Cham\\03_Mapping_output\\Zandt\n"
     ]
    }
   ],
   "source": [
    "# List all PDF files in output directory\n",
    "pdf_files = glob.glob(os.path.join(output_dir, \"*.pdf\"))\n",
    "pdf_files = sorted(pdf_files)\n",
    "\n",
    "print(f\"Generated PDF maps ({len(pdf_files)} files):\\n\")\n",
    "for i, pdf_file in enumerate(pdf_files, 1):\n",
    "    file_size = os.path.getsize(pdf_file) / (1024 * 1024)  # MB\n",
    "    print(f\"  {i}. {os.path.basename(pdf_file)} ({file_size:.2f} MB)\")\n",
    "\n",
    "if pdf_files:\n",
    "    print(f\"\\n✓ All maps saved in: {output_dir}\")\n",
    "else:\n",
    "    print(\"\\n⚠ No PDF files were generated.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68132fad",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 📝 Usage Examples\n",
    "\n",
    "### Option 1: Single Vector File\n",
    "```python\n",
    "vector_path = r\"D:\\path\\to\\boundaries.gpkg\"  # or .shp, .kml, .geojson\n",
    "```\n",
    "\n",
    "### Option 2: Vector Folder (Auto-Discovery)\n",
    "```python\n",
    "vector_path = r\"D:\\path\\to\\vector_folder\"  # Will find all .gpkg, .shp, .kml, .geojson files\n",
    "```\n",
    "\n",
    "**How it works:**\n",
    "- For each CHM file, the code checks ALL vector files for overlapping geometries\n",
    "- Only overlapping geometries from all vector files are included in each map\n",
    "- CHMs without any overlapping vectors are automatically skipped\n",
    "- Supports mixing formats: can use .gpkg, .shp, .kml files together!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9d0f14a-ade8-46a2-a442-8b1f6fad3ccd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0fc4ecf-342f-47b9-89f5-737071264c80",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79bcdd2d-5c84-45c5-85af-a139c8f800ae",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
